{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# basic_train"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`basic_train` wraps together the data (in a [<code>DataBunch</code>](fastai.data.html#DataBunch) object) with a pytorch model to define a [<code>Learner</code>](fastai.basic_train.html#Learner) object. This is where the basic training loop is defined in the [<code>fit</code>](fastai.basic_train.html#fit) function. The [<code>Learner</code>](fastai.basic_train.html#Learner) object is the entry point of most of the [<code>Callback</code>](fastai.callback.html#Callback) functions that will customize this training loop in different ways, notably:\n\n - `Learner.lr_find` will launch an LR range test that will help you select a good learning rate\n - `Learner.fit_one_cycle` will launch a training using the 1cycle policy, to help you train your model fast.\n - `Learner.to_fp16` will convert your model in half precision and halp you launch a training in mixed precision."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": "from fastai.gen_doc.nbdoc import *\nfrom fastai.basic_train import * "
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Global Variable Definitions:"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`default_lr = slice(3e-3)` <div style=\"text-align: right\"><a href=\"../fastai/basic_train.py#L10\">[source]</a></div>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`default_wd = 1e-2` <div style=\"text-align: right\"><a href=\"../fastai/basic_train.py#L11\">[source]</a></div>"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=fit></a>**fit**(<em>epochs</em>=int, <em>model</em>=torch.nn.modules.module.Module, <em>loss_fn</em>: torch.Tensor],=Callable[[torch.Tensor,, <em>opt</em>=torch.optim.optimizer.Optimizer, <em>data</em>=fastai.data.DataBunch, <em>callbacks</em>: NoneType]=Union[Collection[fastai.callback.Callback],, <em>metrics</em>: numbers.Number]],=Union[Collection[Union[torch.Tensor,)\n\n\nFit the `model` on `data` and learn using `loss` and `opt`",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(fit)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[<code>fit</code>](fastai.basic_train.html#fit)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "### <a id=Learner></a><em>class</em> **Learner**(<em>model</em>=torch.nn.modules.module.Module, <em>opt_fn</em>: functools.partial(<class=Callable, <em>loss_fn</em>: <function=Callable, <em>metrics</em>: None=Collection[Callable], <em>true_wd</em>: True=bool, <em>bn_wd</em>: True=bool, <em>wd</em>: Collection[float]]=Union[float,, <em>train_bn</em>: True=bool, <em>path</em>: None=str, <em>model_dir</em>: 'models'=str, <em>callback_fns</em>: None=Collection[Callable], <em>callbacks</em>: <factory>=Collection[fastai.callback.Callback], <em>layer_groups</em>: None=Collection[torch.nn.modules.module.Module])\n\n\nObject that wraps together some data, a model, a loss function and an optimizer",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[<code>Learner</code>](fastai.basic_train.html#Learner)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=create_opt></a>**create_opt**(<em>self</em>, <em>lr</em>: Collection[float]]=Union[float,, <em>wd</em>: Collection[float]]=Union[float,)\n\n\ncreate optimizer with `lr` learning rate and `wd` weight decay",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.create_opt)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.create_opt`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=fit></a>**fit**(<em>self</em>, <em>epochs</em>=int, <em>lr</em>: Collection[float],=Union[float,, <em>wd</em>: Collection[float]]=Union[float,, <em>callbacks</em>: None=Collection[fastai.callback.Callback])\n\n\nfit the model on this learner with `lr` learning rate, `wd` weight decay for `epochs` with `callbacks`",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.fit)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.fit`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=fit_one_cycle></a>**fit_one_cycle**(<em>learn</em>, <em>cyc_len</em>=fastai.basic_train.Learner, <em>max_lr</em>: Collection[float],=int, <em>moms</em>: float]=Union[float,, <em>div_factor</em>: 25.0=Tuple[float,, <em>pct_start</em>: 0.3=float, <em>wd</em>: None=float, <em>**kwargs</em>=float)\n\n\nFits a model following the 1cycle policy",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.fit_one_cycle)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.fit_one_cycle`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=freeze></a>**freeze**(<em>self</em>)\n\n\nfreeze up to last layer",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.freeze)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.freeze`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=freeze_to></a>**freeze_to**(<em>self</em>, <em>n</em>=int)\n\n\nfreeze layers up to layer `n`",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.freeze_to)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.freeze_to`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=_learn_get_preds></a>**_learn_get_preds**(<em>learn</em>=fastai.basic_train.Learner, <em>is_test</em>: False=bool)\n\n\nWrapper of get_preds for learner",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.get_preds)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.get_preds`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=init></a>**init**(<em>self</em>, <em>init</em>)",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.init)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.init`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=load></a>**load**(<em>self</em>, <em>name</em>: str]=Union[pathlib.Path,)\n\n\nload model `name` from `self.model_dir",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.load)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.load`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=cross_entropy></a>**cross_entropy**(<em>input</em>, <em>target</em>, <em>weight</em>=None, <em>size_average</em>=None, <em>ignore_index</em>=-100, <em>reduce</em>=None, <em>reduction</em>='elementwise_mean')\n\n\nfunction.\n\nSee :class:`~torch.nn.CrossEntropyLoss` for details.\n\nArgs:\n    input (Tensor) : :math:`(N, C)` where `C = number of classes` or :math:`(N, C, H, W)`\n        in case of 2D Loss, or :math:`(N, C, d_1, d_2, ..., d_K)` where :math:`K > 1`\n        in the case of K-dimensional loss.\n    target (Tensor) : :math:`(N)` where each value is :math:`0 \\leq \\text{targets}[i] \\leq C-1`,\n        or :math:`(N, d_1, d_2, ..., d_K)` where :math:`K \\geq 1` for\n        K-dimensional loss.\n    weight (Tensor, optional): a manual rescaling weight given to each\n        class. If given, has to be a Tensor of size `C`\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when reduce is ``False``. Default: ``True``\n    ignore_index (int, optional): Specifies a target value that is ignored\n        and does not contribute to the input gradient. When :attr:`size_average` is\n        ``True``, the loss is averaged over non-ignored targets. Default: -100\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (string, optional): Specifies the reduction to apply to the output:\n        'none' | 'elementwise_mean' | 'sum'. 'none': no reduction will be applied,\n        'elementwise_mean': the sum of the output will be divided by the number of\n        elements in the output, 'sum': the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: 'elementwise_mean'\n\nExamples::\n\n    >>> input = torch.randn(3, 5, requires_grad=True)\n    >>> target = torch.randint(5, (3,), dtype=torch.int64)\n    >>> loss = F.cross_entropy(input, target)\n    >>> loss.backward()",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.loss_fn)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.loss_fn`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=lr_find></a>**lr_find**(<em>learn</em>=fastai.basic_train.Learner, <em>start_lr</em>: 1e-05=float, <em>end_lr</em>: 10=float, <em>num_it</em>: 100=int, <em>**kwargs</em>=Any)\n\n\nExplore lr from `start_lr` to `end_lr` over `num_it` iterations of `learn`",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.lr_find)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.lr_find`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=lr_range></a>**lr_range**(<em>self</em>, <em>lr</em>: slice]=Union[float,)\n\n\nBuild learning rate schedule",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.lr_range)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.lr_range`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=mixup></a>**mixup**(<em>learn</em>=fastai.basic_train.Learner, <em>alpha</em>: 0.4=float, <em>stack_x</em>: False=bool, <em>stack_y</em>: True=bool)\n\n\nAdds mixup https://arxiv.org/abs/1710.09412 to the learner",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.mixup)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.mixup`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=pred_batch></a>**pred_batch**(<em>learn</em>=fastai.basic_train.Learner, <em>is_valid</em>: True=bool)\n\n\nReturns input, target and output of the model on a batch",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.pred_batch)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.pred_batch`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=save></a>**save**(<em>self</em>, <em>name</em>: str]=Union[pathlib.Path,)\n\n\nsave model with `name` to `self.model_dir`",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.save)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.save`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=split></a>**split**(<em>self</em>, <em>split_on</em>: Collection[Collection[torch.nn.modules.module.Module]]]=Union[Callable,)\n\n\nsplit the model at `split_on`",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.split)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.split`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=to_fp16></a>**to_fp16**(<em>learn</em>=fastai.basic_train.Learner, <em>loss_scale</em>: 512.0=float, <em>flat_master</em>: False=bool)\n\n\nTransforms the learner in FP16 precision",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.to_fp16)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.to_fp16`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=_TTA></a>**_TTA**(<em>learn</em>=fastai.basic_train.Learner, <em>beta</em>: 0.4=float, <em>scale</em>: 1.35=float, <em>is_test</em>: False=bool)",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.TTA)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.TTA`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=_tta_only></a>**_tta_only**(<em>learn</em>=fastai.basic_train.Learner, <em>is_test</em>: False=bool, <em>scale</em>: 1.25=float)\n\n\nComputes the outputs for several augmented inputs for TTA",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.tta_only)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.tta_only`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=unfreeze></a>**unfreeze**(<em>self</em>)\n\n\nunfreeze entire model",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Learner.unfreeze)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Learner.unfreeze`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "### <a id=LearnerCallback></a><em>class</em> **LearnerCallback**() :: Inherits from (`Callback`)\n\n\nBase class for creating callbacks for the `Learner`",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(LearnerCallback)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[<code>LearnerCallback</code>](fastai.basic_train.html#LearnerCallback)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=loss_batch></a>**loss_batch**(<em>model</em>=torch.nn.modules.module.Module, <em>xb</em>=torch.Tensor, <em>yb</em>=torch.Tensor, <em>loss_fn</em>: torch.Tensor],=Union[Callable[[torch.Tensor,, <em>opt</em>: NoneType]=Union[torch.optim.optimizer.Optimizer,, <em>cb_handler</em>: NoneType]=Union[fastai.callback.CallbackHandler,, <em>metrics</em>: numbers.Number]],=Union[Collection[Union[torch.Tensor,)\n\n\nCalculate loss for a batch, calculate metrics, call out to callbacks as necessary",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(loss_batch)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[<code>loss_batch</code>](fastai.basic_train.html#loss_batch)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "### <a id=Recorder></a><em>class</em> **Recorder**() :: Inherits from (`LearnerCallback`)\n\n\nA `LearnerCallback` that records epoch,loss,opt and metric data during training",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Recorder)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[<code>Recorder</code>](fastai.basic_train.html#Recorder)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=format_stats></a>**format_stats**(<em>self</em>, <em>stats</em>: numbers.Number]]=Collection[Union[torch.Tensor,)",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Recorder.format_stats)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Recorder.format_stats`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=on_backward_begin></a>**on_backward_begin**(<em>self</em>, <em>smooth_loss</em>=torch.Tensor, <em>**kwargs</em>=Any)\n\n\nRecord the loss before any other callback has a chance to modify it.",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Recorder.on_backward_begin)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Recorder.on_backward_begin`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=on_batch_begin></a>**on_batch_begin**(<em>self</em>, <em>**kwargs</em>=Any)\n\n\nRecord learning rate and momentum at beginning of batch",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Recorder.on_batch_begin)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Recorder.on_batch_begin`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=on_epoch_end></a>**on_epoch_end**(<em>self</em>, <em>epoch</em>=int, <em>num_batch</em>=int, <em>smooth_loss</em>=torch.Tensor, <em>last_metrics</em>: numbers.Number]]=typing.Collection[typing.Union[torch.Tensor,, <em>**kwargs</em>=Any)\n\n\nSave epoch info: num_batch, smooth_loss, metrics",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Recorder.on_epoch_end)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Recorder.on_epoch_end`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=on_train_begin></a>**on_train_begin**(<em>self</em>, <em>pbar</em>: fastprogress.fastprogress.ProgressBar]=Union[fastprogress.fastprogress.MasterBar,, <em>metrics</em>: torch.Tensor],=Collection[Callable[[torch.Tensor,, <em>**kwargs</em>=Any)\n\n\nInitialize recording status at beginning of training",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Recorder.on_train_begin)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Recorder.on_train_begin`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=plot></a>**plot**(<em>self</em>, <em>skip_start</em>: 10=int, <em>skip_end</em>: 5=int)\n\n\nPlot learning rate and losses, trimmed between `skip_start` and `skip_end`",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Recorder.plot)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Recorder.plot`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=plot_losses></a>**plot_losses**(<em>self</em>)\n\n\nPlot training and validation losses",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Recorder.plot_losses)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Recorder.plot_losses`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=plot_lr></a>**plot_lr**(<em>self</em>, <em>show_moms</em>=False)\n\n\nPlot learning rate, `show_moms` to include momentum",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Recorder.plot_lr)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Recorder.plot_lr`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=plot_metrics></a>**plot_metrics**(<em>self</em>)\n\n\nPlot metrics collected during training",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Recorder.plot_metrics)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Recorder.plot_metrics`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=train_epoch></a>**train_epoch**(<em>model</em>=torch.nn.modules.module.Module, <em>dl</em>=torch.utils.data.dataloader.DataLoader, <em>opt</em>=torch.optim.optimizer.Optimizer, <em>loss_func</em>: torch.Tensor],=Callable[[torch.Tensor,)\n\n\nSimple training of `model` for 1 epoch of `dl` using optim `opt` and loss function `loss_func`",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(train_epoch)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[<code>train_epoch</code>](fastai.basic_train.html#train_epoch)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=validate></a>**validate**(<em>model</em>=torch.nn.modules.module.Module, <em>dl</em>=torch.utils.data.dataloader.DataLoader, <em>loss_fn</em>: torch.Tensor],=Union[Callable[[torch.Tensor,, <em>metrics</em>: numbers.Number]],=Union[Collection[Union[torch.Tensor,, <em>cb_handler</em>: NoneType]=Union[fastai.callback.CallbackHandler,, <em>pbar</em>: fastprogress.fastprogress.ProgressBar,=Union[fastprogress.fastprogress.MasterBar,)\n\n\nCalculate loss and metrics for the validation set",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(validate)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[<code>validate</code>](fastai.basic_train.html#validate)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
