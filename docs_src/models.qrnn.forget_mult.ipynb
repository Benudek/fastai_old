{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# models.qrnn.forget_mult"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Type an introduction of the package here."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": "from fastai.gen_doc.nbdoc import *\nfrom fastai.models.qrnn.forget_mult import * "
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Global Variable Definitions:"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`kernel = '''` <div style=\"text-align: right\"><a href=\"../fastai/models/qrnn/forget_mult.py#L11\">[source]</a></div>"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "### <a id=CPUForgetMult></a><em>class</em> `CPUForgetMult`() :: Inherits ([<code>Module</code>](https://pytorch.org/docs/stable/nn.html#torch.nn.Module))<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/models/qrnn/forget_mult.py#L76\">[source]</a></div>\n\n\nYour models should also subclass this class.\n\nModules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::\n\n    import torch.nn as nn\n    import torch.nn.functional as F\n\n    class Model(nn.Module):\n        def __init__(self):\n            super(Model, self).__init__()\n            self.conv1 = nn.Conv2d(1, 20, 5)\n            self.conv2 = nn.Conv2d(20, 20, 5)\n\n        def forward(self, x):\n           x = F.relu(self.conv1(x))\n           return F.relu(self.conv2(x))\n\nSubmodules assigned in this way will be registered, and will have their\nparameters converted too when you call :meth:`to`, etc.",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(CPUForgetMult)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[<code>CPUForgetMult</code>](http://docs.fast.ai/models.qrnn.forget_mult.html#CPUForgetMult)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=forward></a>`forward`(<code>f</code>, <code>x</code>, <code>hidden_init</code>=`None`)<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/models/qrnn/forget_mult.py#L80\">[source]</a></div>\n\n\nShould be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them.",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(CPUForgetMult.forward)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`CPUForgetMult.forward`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "### <a id=ForgetMult></a><em>class</em> `ForgetMult`() :: Inherits ([<code>Module</code>](https://pytorch.org/docs/stable/nn.html#torch.nn.Module))<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/models/qrnn/forget_mult.py#L158\">[source]</a></div>\n\n\nh_t = f_t * x_t + (1 - f_t) * h_{t-1}\n\nThis equation is equivalent to dynamic weighted averaging.\n\nInputs: X, hidden\n    - X (seq_len, batch, input_size): tensor containing the features of the input sequence.\n    - F (seq_len, batch, input_size): tensor containing the forget gate values, assumed in range [0, 1].\n    - hidden_init (batch, input_size): tensor containing the initial hidden state for the recurrence (h_{t-1}).\n    - use_cuda: If True, use the fast element-wise CUDA kernel for recurrence. If False, uses naive for loop. Default: True.",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(ForgetMult)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[<code>ForgetMult</code>](http://docs.fast.ai/models.qrnn.forget_mult.html#ForgetMult)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=forward></a>`forward`\n(<code>f</code>, <code>x</code>, <code>hidden_init</code>=`None`, <code>use_cuda</code>=`True`)<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/models/qrnn/forget_mult.py#L174\">[source]</a></div>\n\n\nShould be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them.",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(ForgetMult.forward)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`ForgetMult.forward`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "### <a id=GPUForgetMult></a><em>class</em> `GPUForgetMult`() :: Inherits ([<code>Function</code>](https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function))<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/models/qrnn/forget_mult.py#L96\">[source]</a></div>\n\n\nEvery operation performed on :class:`Tensor` s creates a new function\nobject, that performs the computation, and records that it happened.\nThe history is retained in the form of a DAG of functions, with edges\ndenoting data dependencies (``input <- output``). Then, when backward is\ncalled, the graph is processed in the topological ordering, by calling\n:func:`backward` methods of each :class:`Function` object, and passing\nreturned gradients on to next :class:`Function` s.\n\nNormally, the only way users interact with functions is by creating\nsubclasses and defining new operations. This is a recommended way of\nextending torch.autograd.\n\nEach function object is meant to be used only once (in the forward pass).\n\nExamples::\n\n    >>> class Exp(Function):\n    >>>\n    >>>     @staticmethod\n    >>>     def forward(ctx, i):\n    >>>         result = i.exp()\n    >>>         ctx.save_for_backward(result)\n    >>>         return result\n    >>>\n    >>>     @staticmethod\n    >>>     def backward(ctx, grad_output):\n    >>>         result, = ctx.saved_tensors\n    >>>         return grad_output * result",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(GPUForgetMult)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[<code>GPUForgetMult</code>](http://docs.fast.ai/models.qrnn.forget_mult.html#GPUForgetMult)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=backward></a>`backward`(<code>grad_h</code>)<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/models/qrnn/forget_mult.py#L138\">[source]</a></div>\n\n\nThis function is to be overridden by all subclasses.\n\nIt must accept a context :attr:`ctx` as the first argument, followed by\nas many outputs did :func:`forward` return, and it should return as many\ntensors, as there were inputs to :func:`forward`. Each argument is the\ngradient w.r.t the given output, and each returned value should be the\ngradient w.r.t. the corresponding input.\n\nThe context can be used to retrieve tensors saved during the forward\npass. It also has an attribute :attr:`ctx.needs_input_grad` as a tuple\nof booleans representing whether each input needs gradient. E.g.,\n:func:`backward` will have ``ctx.needs_input_grad[0] = True`` if the\nfirst input to :func:`forward` needs gradient computated w.r.t. the\noutput.",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(GPUForgetMult.backward)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`GPUForgetMult.backward`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=compile></a>`compile`()<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/models/qrnn/forget_mult.py#L102\">[source]</a></div>",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(GPUForgetMult.compile)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`GPUForgetMult.compile`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=forward></a>`forward`(<code>f</code>, <code>x</code>, <code>hidden_init</code>=`None`)<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/models/qrnn/forget_mult.py#L122\">[source]</a></div>\n\n\nThis function is to be overridden by all subclasses.\n\nIt must accept a context ctx as the first argument, followed by any\nnumber of arguments (tensors or other types).\n\nThe context can be used to store tensors that can be then retrieved\nduring the backward pass.",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(GPUForgetMult.forward)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`GPUForgetMult.forward`"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
